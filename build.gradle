/**
 * Copyright 2017 LinkedIn Corporation. All rights reserved. Licensed under the BSD-2 Clause license.
 * See LICENSE in the project root for license information.
 */
buildscript {
  repositories {
    maven {
      url "https://plugins.gradle.org/m2/"
    }
  }
  dependencies {
    // license-gradle plugin: https://github.com/hierynomus/license-gradle-plugin
    classpath "gradle.plugin.nl.javadude.gradle.plugins:license-gradle-plugin:0.14.0"
  }
}

plugins {
  id "org.shipkit.java" version "2.1.3"
}

def hadoopVersion = '2.7.7'
ext.deps = [
  hadoop: [
    hdfs: "org.apache.hadoop:hadoop-hdfs:${hadoopVersion}",
    common: "org.apache.hadoop:hadoop-common:${hadoopVersion}",
    'yarn-api': "org.apache.hadoop:hadoop-yarn-api:${hadoopVersion}",
    'yarn-client': "org.apache.hadoop:hadoop-yarn-client:${hadoopVersion}",
    'yarn-common': "org.apache.hadoop:hadoop-yarn-common:${hadoopVersion}",
    'mapreduce-client-core': "org.apache.hadoop:hadoop-mapreduce-client-core:${hadoopVersion}",
    minicluster: "org.apache.hadoop:hadoop-minicluster:${hadoopVersion}",
    'hdfs-test': "org.apache.hadoop:hadoop-hdfs:${hadoopVersion}:tests",
    'common-test': "org.apache.hadoop:hadoop-common:${hadoopVersion}:tests",
    'yarn-server-test': "org.apache.hadoop:hadoop-yarn-server-tests:${hadoopVersion}:tests",
  ]
]

allprojects {
  group = 'com.linkedin.dynamometer'
}

if (project.hasProperty('overrideBuildEnvironment')) {
  // Allow for override of the environment via a property flag
  apply from: project.overrideBuildEnvironment
  final File overrideFile = rootProject.file(project.overrideBuildEnvironment)
  assert overrideFile.isFile() : "The environment script ($overrideFile) does not exist or is not a file"
  apply from: overrideFile
} else {
  apply from: 'defaultEnvironment.gradle'
}

subprojects {
  apply plugin: 'java'
  apply plugin: 'eclipse'
  apply plugin: 'idea'
  apply plugin: 'license'

  sourceCompatibility = 1.8

  license {
    header rootProject.file('license_header')
    // Set the year in the license
    ext.year = Calendar.getInstance().get(Calendar.YEAR)
    skipExistingHeaders = true
    strictCheck = true
  }

  configurations {
    hadoopRuntime.extendsFrom(runtime)
    hadoopRuntime {
      exclude group: 'org.apache.hadoop'
    }
  }

}

apply plugin: 'distribution'

// Generates a closure which is used to set up the contents
// for a distribution; parametrized by the name of the
// configuration to include in the lib directory.
def generateDistContents(configurationName) {
  return {
    into('.') {
      from rootProject.fileTree('.') {
        include 'README.md'
        include 'LICENSE'
        include 'NOTICE'
        include 'CONTRIBUTING.md'
      }
    }
    into('bin') {
      def bashFiles = []
      rootProject.subprojects.each {
        bashFiles << it.fileTree("src/main/bash") {
          include "*.sh"
        }
      }
      from bashFiles
    }
    into('lib') {
      def dependencies = files()
      def jars = []
      rootProject.subprojects.each {
        // Use subtraction to eliminate duplicates
        dependencies = dependencies + (it.configurations[configurationName] - dependencies)
        jars << it.jar
      }
      from dependencies
      from jars
    }
  }
}

distributions {
  // main distribution does not include Hadoop JARs; this is the one
  // typically expected to be used on a system properly set up with
  // an existing Hadoop installation.
  main {
    baseName = rootProject.name
    contents generateDistContents('hadoopRuntime')
  }
  // fat distribution includes all dependencies.
  fat {
    baseName = rootProject.name + '-fat'
    contents generateDistContents('runtime')
  }
}

build.dependsOn(distZip)
